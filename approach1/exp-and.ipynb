{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, redirect, url_for,send_from_directory, render_template_string\n",
    "from werkzeug.utils import secure_filename\n",
    "import caffe\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train: 2182 Test:243\n",
    "Ratio: 9:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployPrototxt = \"/opt/swm-ml-docker/swm-ml-master/bvlc_reference_caffenet/deploy.prototxt\"\n",
    "caffeModel = \"/opt/swm-ml-docker/swm-ml-master/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel\"\n",
    "featureVectorDirectory = \"/opt/swm-ml-docker/data/train\"\n",
    "metadataDirectory = '/opt/swm-ml-docker/metadata_bak/'\n",
    "imageMeanFile = '/opt/swm-ml-docker/ilsvrc_2012_mean.npy'\n",
    "layerName = 'fc7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n",
      "Done loading\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model ...\")\n",
    "cnn = caffe.Net(deployPrototxt, caffe.TEST, weights=caffeModel)\n",
    "print(\"Done loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to accept one image at a time.\n",
    "(_, c, w, h) = cnn.blobs['data'].data.shape\n",
    "cnn.blobs['data'].reshape(1, c, w, h)\n",
    "transformer = caffe.io.Transformer({'data': cnn.blobs['data'].data.shape})\n",
    "transformer.set_mean('data', np.load(imageMeanFile).mean(1).mean(1))\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "transformer.set_raw_scale('data', 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFeatureVectors(dirPath, d):\n",
    "    \"\"\"\n",
    "    Loads all feature vectors from the local directory into a single nxd matrix\n",
    "    where n is the number of feature vectors and the d is the dimensionality.\n",
    "    Returns the matrix and a list of file names in one-to-one correspondence\n",
    "    with the rows of the matrix.\n",
    "    \"\"\"\n",
    "    allFiles = os.listdir(dirPath)\n",
    "    data = np.zeros([len(allFiles), d])\n",
    "    for i, fileName in enumerate(allFiles):\n",
    "        with open(\"%s/%s\" % (dirPath, fileName), \"rb\") as inputFile:\n",
    "            data[i] = struct.unpack('f'*d, inputFile.read())\n",
    "    return (data, allFiles)\n",
    "\n",
    "def loadMetaData(metadataDir):\n",
    "    metadataByImageHash = {}\n",
    "    allFiles = os.listdir(metadataDir)\n",
    "    for fileName in allFiles:\n",
    "        with open(\"%s/%s\" % (metadataDir, fileName), \"r\") as jsonFile:\n",
    "            metadata = json.load(jsonFile)\n",
    "            metadataByImageHash[metadata['Image Hash']] = metadata\n",
    "    return metadataByImageHash\n",
    "\n",
    "# Simple case\n",
    "def makeBinaryLabels(metadataByImageHash, allImageHashes):\n",
    "    labels = []\n",
    "    for imageHash in allImageHashes:\n",
    "        metadata = metadataByImageHash[imageHash]\n",
    "        labels.append(1 if (metadata['Secondary'] == \"NA\") else 0)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM\n",
      "Finished training ready to classify images\n"
     ]
    }
   ],
   "source": [
    "print(\"Training SVM\")\n",
    "data, allImageHashes = loadFeatureVectors(featureVectorDirectory, d = 4096)\n",
    "metadataByImageHash = loadMetaData(metadataDirectory)\n",
    "labels = makeBinaryLabels(metadataByImageHash, allImageHashes)\n",
    "clf = svm.SVC(probability=True)\n",
    "clf.fit(data, labels)\n",
    "print(\"Finished training ready to classify images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureVectorTestDirectory = \"/opt/swm-ml-docker/data/test\"\n",
    "dataTest, allImageHashesTest = loadFeatureVectors(featureVectorTestDirectory, d = 4096)\n",
    "labelsTest = makeBinaryLabels(metadataByImageHash, allImageHashesTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80246913580246915"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(dataTest,labelsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=clf.predict(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-244b61dbf20c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelsTest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "CM = metrics.confusion_matrix(labelsTest,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr,tpr,thesholds=metrics.roc_curve(labelsTest,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "caffe --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "file=open(\"FP.txt\",'w')\n",
    "while i<len(prediction):\n",
    "    if prediction[i]==1 and labelsTest[i]==0:\n",
    "        file.write(str(i))\n",
    "        file.write('\\n')\n",
    "    i=i+1\n",
    "file.close()        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath1=\"/opt/swm-ml-docker/data/test.txt\"\n",
    "filepath2=\"/opt/swm-ml-docker/data/FP.txt\"\n",
    "file=open(\"FP_imageName.txt\",'w')\n",
    "l=[]\n",
    "with open(filepath2,'r') as fp:\n",
    "    for line in fp:\n",
    "        l.append(int(line))\n",
    "\n",
    "i=0\n",
    "FPImageHashes=[]\n",
    "with open(filepath1,'r') as fp:\n",
    "    for line in fp:\n",
    "        if i in l:\n",
    "            line = line.strip('\\n')\n",
    "            file.write(line+\".jpg\")\n",
    "            file.write('\\n')\n",
    "            FPImageHashes.append(line)\n",
    "        i=i+1\n",
    "file.close()               \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageName=[]\n",
    "file=open(\"imageName.txt\",'w')\n",
    "for i in FPImageHashes:\n",
    "    metadata=metadataByImageHash[i]\n",
    "    file.write(metadata[\"Image Name\"])\n",
    "    file.write('\\n')\n",
    "    GoogleIds.append(metadata[\"Image Name\"])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
