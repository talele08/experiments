{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-image in /usr/local/lib/python2.7/dist-packages\n",
      "Requirement already up-to-date: PyWavelets>=0.4.0 in /usr/local/lib/python2.7/dist-packages (from scikit-image)\n",
      "Requirement already up-to-date: scipy>=0.17.0 in /usr/local/lib/python2.7/dist-packages (from scikit-image)\n",
      "Requirement already up-to-date: networkx>=1.8 in /usr/local/lib/python2.7/dist-packages (from scikit-image)\n",
      "Requirement already up-to-date: six>=1.7.3 in /usr/local/lib/python2.7/dist-packages (from scikit-image)\n",
      "Requirement already up-to-date: matplotlib>=1.3.1 in /usr/local/lib/python2.7/dist-packages (from scikit-image)\n",
      "Requirement already up-to-date: pillow>=2.1.0 in /usr/local/lib/python2.7/dist-packages (from scikit-image)\n",
      "Requirement already up-to-date: numpy>=1.9.1 in /usr/local/lib/python2.7/dist-packages (from PyWavelets>=0.4.0->scikit-image)\n",
      "Requirement already up-to-date: decorator>=4.1.0 in /usr/local/lib/python2.7/dist-packages (from networkx>=1.8->scikit-image)\n",
      "Requirement already up-to-date: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already up-to-date: backports.functools-lru-cache in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already up-to-date: subprocess32 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already up-to-date: pytz in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already up-to-date: python-dateutil>=2.1 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already up-to-date: kiwisolver>=1.0.1 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already up-to-date: cycler>=0.10 in /usr/local/lib/python2.7/dist-packages (from matplotlib>=1.3.1->scikit-image)\n",
      "Requirement already up-to-date: setuptools in /usr/local/lib/python2.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.3.1->scikit-image)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "import pandas\n",
    "from sklearn import svm,metrics\n",
    "from __future__ import division\n",
    "import os\n",
    "import numpy as np\n",
    "import struct\n",
    "from sklearn.multiclass import OneVsRestClassifier,OneVsOneClassifier\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from skimage import io; io.use_plugin('matplotlib')\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import csv\n",
    "import os\n",
    "import shutil\n",
    "import imghdr\n",
    "from sklearn.externals import joblib\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfilepath='/opt/pgr/appgrimage.csv'\n",
    "trainfilepath='/opt/pgr/exp2/train.txt'\n",
    "testfilepath='/opt/pgr/exp2/test.txt'\n",
    "featureVectorDir='/opt/pgr/exp2/featureVectors-4096'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the filename and complaint type as list\n",
    "with open(csvfilepath) as csvfile:\n",
    "    csvReader=csv.reader(csvfile,delimiter=',')\n",
    "    complainType=[]\n",
    "    imageName=[]\n",
    "    for row in csvReader:\n",
    "        complainType.append(row[1])\n",
    "        imageName.append(row[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Removal of Debris': 11449, 'Desilting of Drain': 6102, 'Removal of garbage': 1615, 'Non Burning of Street Lights': 1511, 'Stagnation of water': 1173, 'Improper Sweeping': 752, 'Over flowing of garbage bins': 716, 'Disposal of removed silt on the Road': 663, 'Absenteesim of sweepers': 596, 'UGD Over Flow': 583, 'Broken Bin': 575, 'Absenteesim of door to door garbage collector': 515, 'Unsanitary conditions on the road': 437, 'Pot hole fill up/Repairs to the damage surface': 420, 'Water pipe leakage': 401, 'Mosquito menace': 370, 'Unauthorised / Illegal construction': 361, 'Burning of garbage': 337, 'Stray Pigs': 335, 'Provision of garbage bin': 327, 'Illegal draining of sewage to SWD/Open site': 286, 'Encroachment on the public property': 279, 'Bio Medical waste/Health hazard waste removal': 277, 'Dog menace': 271, 'Obstruction of water flow': 259, 'Open defecation- free (ODF)': 237, 'Issues Related to Drinking Water Supply': 230, 'Complaints regarding public toilets': 199, 'Repairs to Flyovers/ bridges/ Culverts': 180, 'Stoppage of Civil Works': 163, 'Poor quality of work': 156, 'Fevers - Dengue/Malaria/ Gastro-enteritis': 154, 'Complaints related to property tax': 133, 'Issues relating to Vacant lands': 129, 'Death of Stray Animals': 127, 'Repairs to existing footpath': 122, 'Hanging of Streetlight Wires': 122, 'Community Toilets': 115, 'Repair Bore wells': 114, 'Shifting of garbage bin': 104, 'Unauthorised Road cutting': 102, 'Removal of shops in the footpath': 93, 'Silt by the side of dividers': 92, 'Obstruction of road by Trees branches': 82, 'Electric Shock due to street light': 81, 'Transfer of Title of property': 68, 'Complaints regarding Schools': 66, 'Complaints regarding Dispensary': 58, 'Parking Issue': 51, 'Contamination of Water': 47, 'Complaints regarding burial ground': 47, 'Replacement of Cover for Manholes': 43, 'Repairs to Centre Median': 43, 'Repairs to the SWD': 42, 'Request for Anti Larval operations - to prevent  Dengue /Malaria etc': 42, 'Complaint Regarding School Toilets': 41, 'Errors in demand Notice': 38, 'Complaints related to issue of all types of license': 37, 'Maintenance of Parks': 35, 'Removal of fallen trees': 34, 'Violation of DCR/Building bye laws': 33, 'Garbage lorry with out Net': 32, 'Inclusion': 28, 'New Property Tax Fixation': 28, 'Non Receipt of Pensions (Disabled/ Old age/ Widow)': 26, 'Transfer Station Smell': 26, 'Food adulteration: Road Side Eateries': 24, 'Complaints regarding function Halls': 23, 'Spilling of Garbage from lorry': 22, 'Poor maintenance of Public toilets at Fuel stations': 19, 'Stray cattle': 17, 'Unauthorised sale of meat and meat product': 16, 'Property Tax Bifurcation': 16, 'Issues relating to Advertisement Boards': 15, 'Revision Petition on Property Tax': 15, 'Double Assessments': 14, 'Unhygeinic conditions because of Slaughter House': 13, 'Complaints regarding Voter list': 13, 'New Vacant Land tax Fixation': 11, 'Unauthorised tree Cutting': 11, 'New Street light': 9, 'Sanction of Gas Connection Under Deepam Scheme': 9, 'Complaints regarding restaurants / Function halls': 8, 'Illegal slaughtering': 7, 'Repairs to Traffic Island': 7, 'Over head cable Wires running in Hapazard manner': 6, 'Vaddi Leni Runalu': 5, 'Disputes in SSG / SLF / TLF': 5, 'Complaints regarding all Sanctioned loans': 4, 'Formation of New Road': 3, 'Maintenance of Playground': 3, 'Non Sanction of Bank Linkage to the group': 3, 'Misuse of Community Hall': 3, 'Public Health and Sanitation-Others': 3, 'Unclaimed Dead Bodies': 2, 'New Drain Construction': 2, 'Unauthorised Advt. Boards': 2, 'Unhygienic and improper transport of meat and livestock': 1, 'ram': 1, 'Vacancy Remission': 1, 'Town Planning-Others': 1})\n"
     ]
    }
   ],
   "source": [
    "count=collections.Counter(complainType)\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing the frequencies of each label in csv file\n",
    "with open('frequency.csv','w') as csvfile:\n",
    "    fieldnames=['label','count']\n",
    "    writer=csv.writer(csvfile)\n",
    "    writer.writerow(fieldnames)\n",
    "    for key, value in count.items():\n",
    "        writer.writerow([key,value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/pgr/notebooksPGR\n",
      "/opt/pgr\n",
      "appgrimage.csv\n",
      "bagofwords.py\n",
      "copy.sh\n",
      "copy_label_specific.py\n",
      "copy_metadataImages.py\n",
      "data\n",
      "exp1\n",
      "exp2\n",
      "featurevectors.py\n",
      "images_major\n",
      "notebooksPGR\n",
      "pgrimagelist.csv\n",
      "recources\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pwd\n",
    "cd ..\n",
    "pwd\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extracting feature vectors from images\n",
    "#run /opt/pgr/featurevectors.py /opt/pgr/exp2/Images /opt/pgr/recources/deploy.prototxt /opt/pgr/recources/bvlc_reference_caffenet.caffemodel /opt/pgr/recources/ilsvrc_2012_mean.npy fc7 /opt/pgr/exp2/featureVectors-4096 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "#caffe.io.load_image('/opt/pgr/exp2/Images/ea51856b-1fbb-45ff-b121-b9478dceb74b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dictionary of complaint type\n",
    "classlabels={}\n",
    "i=0\n",
    "with open('frequency.csv','r') as csvfile:\n",
    "    csvReader=csv.reader(csvfile,delimiter=',')\n",
    "    for row in csvReader:\n",
    "        if row[0]=='label':\n",
    "            continue\n",
    "        classlabels[row[0]]=i\n",
    "        i+=1\n",
    "        if i==16:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Removal of garbage': 2, 'Pot hole fill up/Repairs to the damage surface': 13, 'Absenteesim of door to door garbage collector': 11, 'Improper Sweeping': 5, 'Broken Bin': 10, 'Stagnation of water': 4, 'Desilting of Drain': 1, 'Absenteesim of sweepers': 8, 'Unsanitary conditions on the road': 12, 'Removal of Debris': 0, 'Over flowing of garbage bins': 6, 'Water pipe leakage': 14, 'Non Burning of Street Lights': 3, 'Disposal of removed silt on the Road': 7, 'Mosquito menace': 15, 'UGD Over Flow': 9}\n"
     ]
    }
   ],
   "source": [
    "print classlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating txt file contaning files with specific labels\n",
    "def createLabelSpecifictxt(src,txtfile,csvFilePath,dest):\n",
    "    List = open(txtfile).readlines()\n",
    "    #print List\n",
    "    data=[]\n",
    "    \n",
    "    for i in range(0,len(List)):\n",
    "        data.append(List[i].strip('\\n'))\n",
    "\n",
    "    with open(dest,'w') as f:\n",
    "        with open(csvFilePath) as csvfile:\n",
    "            readCSV=csv.reader(csvfile,delimiter=',')\n",
    "            labels=[]\n",
    "            imageName=[]\n",
    "            for row in readCSV:\n",
    "                name=row[3]\n",
    "                label=row[1]\n",
    "                fullpath=os.path.join(src,name)\n",
    "                if (os.path.isfile(fullpath) and (label in classlabels) and (name in data)):\n",
    "                     f.write(name)\n",
    "                     f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the extracted feature vectors in an matrix\n",
    "def loadFeatureVectors(dirPath,txtfilepath, d):\n",
    "    allFiles=[]\n",
    "    n = sum(1 for line in open(txtfilepath))\n",
    "    with open(txtfilepath) as fp:\n",
    "        data = np.zeros([n, d])\n",
    "        i=0\n",
    "        for fileName in fp:\n",
    "            fileName=fileName.strip('\\n')\n",
    "            allFiles.append(fileName)\n",
    "            with open(\"%s/%s\" % (dirPath, fileName), \"rb\") as inputFile:\n",
    "                data[i] = struct.unpack('f'*d, inputFile.read())\n",
    "                if(np.all(np.isfinite(data[i]))==False):\n",
    "                    print i\n",
    "                i+=1\n",
    "    return (data, allFiles)\n",
    "\n",
    "# Generating labels of the files with filename in given text file\n",
    "def makelabels(csvfilepath,txtfilepath):\n",
    "    labels=[]\n",
    "    with open(txtfilepath) as fp:\n",
    "        df=pandas.read_csv(csvfilepath,error_bad_lines=False,header=None)\n",
    "        df.columns = [\"City\", \"Complaint Type\", \"Date\", \"FilestoreId\",\"FilePath\",\"Comments\"]\n",
    "        #print df\n",
    "        imageNametoComplainType=dict(zip(df.FilestoreId, df['Complaint Type']))\n",
    "        print len(imageNametoComplainType)\n",
    "        for imageName in fp:\n",
    "                 imageName=imageName.strip('\\n')\n",
    "                 labels.append(classlabels[imageNametoComplainType[imageName]])\n",
    "        #print classlabels[data[\"Complaint Type\"]] \n",
    "    return labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 4248: expected 6 fields, saw 7\n",
      "Skipping line 4249: expected 6 fields, saw 7\n",
      "Skipping line 6909: expected 6 fields, saw 7\n",
      "Skipping line 6910: expected 6 fields, saw 7\n",
      "Skipping line 6911: expected 6 fields, saw 7\n",
      "Skipping line 6912: expected 6 fields, saw 7\n",
      "Skipping line 11651: expected 6 fields, saw 7\n",
      "Skipping line 11700: expected 6 fields, saw 7\n",
      "Skipping line 11701: expected 6 fields, saw 7\n",
      "Skipping line 11702: expected 6 fields, saw 7\n",
      "Skipping line 11840: expected 6 fields, saw 7\n",
      "Skipping line 23326: expected 6 fields, saw 7\n",
      "Skipping line 24704: expected 6 fields, saw 7\n",
      "Skipping line 24754: expected 6 fields, saw 7\n",
      "Skipping line 24962: expected 6 fields, saw 7\n",
      "Skipping line 25259: expected 6 fields, saw 7\n",
      "Skipping line 25380: expected 6 fields, saw 7\n",
      "Skipping line 25517: expected 6 fields, saw 7\n",
      "Skipping line 25892: expected 6 fields, saw 7\n",
      "Skipping line 29076: expected 6 fields, saw 7\n",
      "Skipping line 31093: expected 6 fields, saw 7\n",
      "Skipping line 31094: expected 6 fields, saw 7\n",
      "Skipping line 31095: expected 6 fields, saw 7\n",
      "Skipping line 31098: expected 6 fields, saw 7\n",
      "Skipping line 31615: expected 6 fields, saw 7\n",
      "Skipping line 31716: expected 6 fields, saw 7\n",
      "Skipping line 31945: expected 6 fields, saw 7\n",
      "Skipping line 32637: expected 6 fields, saw 7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 4248: expected 6 fields, saw 7\n",
      "Skipping line 4249: expected 6 fields, saw 7\n",
      "Skipping line 6909: expected 6 fields, saw 7\n",
      "Skipping line 6910: expected 6 fields, saw 7\n",
      "Skipping line 6911: expected 6 fields, saw 7\n",
      "Skipping line 6912: expected 6 fields, saw 7\n",
      "Skipping line 11651: expected 6 fields, saw 7\n",
      "Skipping line 11700: expected 6 fields, saw 7\n",
      "Skipping line 11701: expected 6 fields, saw 7\n",
      "Skipping line 11702: expected 6 fields, saw 7\n",
      "Skipping line 11840: expected 6 fields, saw 7\n",
      "Skipping line 23326: expected 6 fields, saw 7\n",
      "Skipping line 24704: expected 6 fields, saw 7\n",
      "Skipping line 24754: expected 6 fields, saw 7\n",
      "Skipping line 24962: expected 6 fields, saw 7\n",
      "Skipping line 25259: expected 6 fields, saw 7\n",
      "Skipping line 25380: expected 6 fields, saw 7\n",
      "Skipping line 25517: expected 6 fields, saw 7\n",
      "Skipping line 25892: expected 6 fields, saw 7\n",
      "Skipping line 29076: expected 6 fields, saw 7\n",
      "Skipping line 31093: expected 6 fields, saw 7\n",
      "Skipping line 31094: expected 6 fields, saw 7\n",
      "Skipping line 31095: expected 6 fields, saw 7\n",
      "Skipping line 31098: expected 6 fields, saw 7\n",
      "Skipping line 31615: expected 6 fields, saw 7\n",
      "Skipping line 31716: expected 6 fields, saw 7\n",
      "Skipping line 31945: expected 6 fields, saw 7\n",
      "Skipping line 32637: expected 6 fields, saw 7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34496\n"
     ]
    }
   ],
   "source": [
    "# Creating training set labels and data\n",
    "createLabelSpecifictxt(featureVectorDir,trainfilepath,csvfilepath,'/opt/pgr/exp2/train_specific.txt')\n",
    "data,imageNames=loadFeatureVectors(featureVectorDir,'/opt/pgr/exp2/train_specific.txt',d=4096)\n",
    "labels=makelabels(csvfilepath,'/opt/pgr/exp2/train_specific.txt')\n",
    "\n",
    "# Creating testing set labels and data\n",
    "createLabelSpecifictxt(featureVectorDir,testfilepath,csvfilepath,'/opt/pgr/exp2/test_specific.txt')\n",
    "dataTest,imageNamesTest=loadFeatureVectors(featureVectorDir,'/opt/pgr/exp2/test_specific.txt',d=4096)\n",
    "labelsTest=makelabels(csvfilepath,'/opt/pgr/exp2/test_specific.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 4490, 1: 3036, 2: 1057, 3: 934, 4: 554, 6: 525, 9: 474, 10: 375, 8: 323, 5: 318, 13: 288, 12: 250, 7: 243, 15: 238, 14: 236, 11: 220})\n",
      "13561 13561\n"
     ]
    }
   ],
   "source": [
    "count=collections.Counter(labels)\n",
    "print count\n",
    "print len(data),len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store feature vectors with specific labels in matrix\n",
    "def loadFeatureVectorsTwoClass(dirPath,txtfilepath,labels, d):\n",
    "    n = sum(1 for line in open(txtfilepath))\n",
    "    count=collections.Counter(labels)\n",
    "    l=count[0]+count[1]\n",
    "    data = np.zeros([l, d])\n",
    "    labelsInTwoClass=[]\n",
    "    with open(txtfilepath) as fp:\n",
    "        itr=0\n",
    "        for i, fileName in enumerate(fp):\n",
    "            if labels[i]==0 or labels[i]==1:\n",
    "                fileName=fileName.strip('\\n')\n",
    "                with open(\"%s/%s\" % (dirPath, fileName), \"rb\") as inputFile:\n",
    "                        data[itr] = struct.unpack('f'*d, inputFile.read())\n",
    "                        itr+=1\n",
    "                        labelsInTwoClass.append(labels[i])\n",
    "    return (data, labelsInTwoClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataInTwoClass,labelsInTwoClass=loadFeatureVectorsTwoClass(featureVectorDir,'/opt/pgr/exp2/train_specific.txt',labels,d=4096)\n",
    "dataInTwoClassTest,labelsInTwoClassTest=loadFeatureVectorsTwoClass(featureVectorDir,'/opt/pgr/exp2/test_specific.txt',labelsTest,d=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7526, 7526)\n",
      "(1883, 1883)\n"
     ]
    }
   ],
   "source": [
    "#count=collections.Counter(labelsTest)\n",
    "#print count[0]\n",
    "#print count\n",
    "print (len(dataInTwoClass),len(labelsInTwoClass))\n",
    "print (len(dataInTwoClassTest),len(labelsInTwoClassTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the classifier\n",
    "''''\n",
    "clfin2class = svm.SVC(probability=True)\n",
    "clfin2class.fit(dataInTwoClass, labelsInTwoClass)\n",
    "''''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the classifier\n",
    "#joblib.dump(clfin2class, 'twoclasssvm.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the classifier\n",
    "clfin2class = joblib.load('twoclasssvm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88688263409453"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfin2class.score(dataInTwoClassTest,labelsInTwoClassTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted labels of the test data\n",
    "predicted=clfin2class.predict(dataInTwoClassTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1009  103]\n",
      " [ 110  661]]\n"
     ]
    }
   ],
   "source": [
    "CM=metrics.confusion_matrix(labelsInTwoClassTest,predicted)\n",
    "print CM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfRFin2class  = RandomForestClassifier(n_estimators=10, max_depth=5,min_samples_split=5, random_state=0)\n",
    "clfRFin2class = clfRFin2class.fit(dataInTwoClass, labelsInTwoClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8141263940520446"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfRFin2class.score(dataInTwoClassTest,labelsInTwoClassTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generating labels of the files with filename in given text file\n",
    "def maketwoVsAlllabels(csvfilepath,txtfilepath):\n",
    "    labels=[]\n",
    "    with open(txtfilepath) as fp:\n",
    "        df=pandas.read_csv(csvfilepath,error_bad_lines=False,header=None)\n",
    "        df.columns = [\"City\", \"Complaint Type\", \"Date\", \"FilestoreId\",\"FilePath\",\"Comments\"]\n",
    "        #print df\n",
    "        imageNametoComplainType=dict(zip(df.FilestoreId, df['Complaint Type']))\n",
    "        print len(imageNametoComplainType)\n",
    "        for imageName in fp:\n",
    "                 imageName=imageName.strip('\\n')\n",
    "                 complaint=imageNametoComplainType[imageName]\n",
    "                 if complaint != 'Removal of Debris' and complaint != 'Desilting of Drain':\n",
    "                    label=2\n",
    "                 else: label=classlabels[imageNametoComplainType[imageName]]\n",
    "                 labels.append(label)\n",
    "        #print classlabels[data[\"Complaint Type\"]] \n",
    "    return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 4248: expected 6 fields, saw 7\n",
      "Skipping line 4249: expected 6 fields, saw 7\n",
      "Skipping line 6909: expected 6 fields, saw 7\n",
      "Skipping line 6910: expected 6 fields, saw 7\n",
      "Skipping line 6911: expected 6 fields, saw 7\n",
      "Skipping line 6912: expected 6 fields, saw 7\n",
      "Skipping line 11651: expected 6 fields, saw 7\n",
      "Skipping line 11700: expected 6 fields, saw 7\n",
      "Skipping line 11701: expected 6 fields, saw 7\n",
      "Skipping line 11702: expected 6 fields, saw 7\n",
      "Skipping line 11840: expected 6 fields, saw 7\n",
      "Skipping line 23326: expected 6 fields, saw 7\n",
      "Skipping line 24704: expected 6 fields, saw 7\n",
      "Skipping line 24754: expected 6 fields, saw 7\n",
      "Skipping line 24962: expected 6 fields, saw 7\n",
      "Skipping line 25259: expected 6 fields, saw 7\n",
      "Skipping line 25380: expected 6 fields, saw 7\n",
      "Skipping line 25517: expected 6 fields, saw 7\n",
      "Skipping line 25892: expected 6 fields, saw 7\n",
      "Skipping line 29076: expected 6 fields, saw 7\n",
      "Skipping line 31093: expected 6 fields, saw 7\n",
      "Skipping line 31094: expected 6 fields, saw 7\n",
      "Skipping line 31095: expected 6 fields, saw 7\n",
      "Skipping line 31098: expected 6 fields, saw 7\n",
      "Skipping line 31615: expected 6 fields, saw 7\n",
      "Skipping line 31716: expected 6 fields, saw 7\n",
      "Skipping line 31945: expected 6 fields, saw 7\n",
      "Skipping line 32637: expected 6 fields, saw 7\n",
      "\n",
      "Skipping line 4248: expected 6 fields, saw 7\n",
      "Skipping line 4249: expected 6 fields, saw 7\n",
      "Skipping line 6909: expected 6 fields, saw 7\n",
      "Skipping line 6910: expected 6 fields, saw 7\n",
      "Skipping line 6911: expected 6 fields, saw 7\n",
      "Skipping line 6912: expected 6 fields, saw 7\n",
      "Skipping line 11651: expected 6 fields, saw 7\n",
      "Skipping line 11700: expected 6 fields, saw 7\n",
      "Skipping line 11701: expected 6 fields, saw 7\n",
      "Skipping line 11702: expected 6 fields, saw 7\n",
      "Skipping line 11840: expected 6 fields, saw 7\n",
      "Skipping line 23326: expected 6 fields, saw 7\n",
      "Skipping line 24704: expected 6 fields, saw 7\n",
      "Skipping line 24754: expected 6 fields, saw 7\n",
      "Skipping line 24962: expected 6 fields, saw 7\n",
      "Skipping line 25259: expected 6 fields, saw 7\n",
      "Skipping line 25380: expected 6 fields, saw 7\n",
      "Skipping line 25517: expected 6 fields, saw 7\n",
      "Skipping line 25892: expected 6 fields, saw 7\n",
      "Skipping line 29076: expected 6 fields, saw 7\n",
      "Skipping line 31093: expected 6 fields, saw 7\n",
      "Skipping line 31094: expected 6 fields, saw 7\n",
      "Skipping line 31095: expected 6 fields, saw 7\n",
      "Skipping line 31098: expected 6 fields, saw 7\n",
      "Skipping line 31615: expected 6 fields, saw 7\n",
      "Skipping line 31716: expected 6 fields, saw 7\n",
      "Skipping line 31945: expected 6 fields, saw 7\n",
      "Skipping line 32637: expected 6 fields, saw 7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34496\n",
      "34496\n"
     ]
    }
   ],
   "source": [
    "twoVsAllLabels=maketwoVsAlllabels('/opt/pgr/appgrimage.csv','/opt/pgr/exp2/train_specific.txt')\n",
    "twoVsAllLabelsTest=maketwoVsAlllabels('/opt/pgr/appgrimage.csv','/opt/pgr/exp2/test_specific.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13561 13561\n"
     ]
    }
   ],
   "source": [
    "#print twoVsAllLabels\n",
    "print len(data),len(twoVsAllLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three label categories  'Removal of Debris','Desilting of Drain' and others trained using\n",
    "# onevsone svm classifier\n",
    "print(\"start: \",time.time(), time.clock())\n",
    "ovo= OneVsOneClassifier( svm.SVC(probability=True)).fit(data, twoVsAllLabels)\n",
    "print(\"End: \",time.time(), time.clock())\n",
    "# Time taken 109 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['twovsallsvm.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the classifier\n",
    "joblib.dump(ovo, 'twovsallsvm.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8091759205143191"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo.score(dataTest,twoVsAllLabelsTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=ovo.predict(dataTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 920   62  130]\n",
      " [  76  527  168]\n",
      " [ 102  115 1322]]\n"
     ]
    }
   ],
   "source": [
    "CM=metrics.confusion_matrix(twoVsAllLabelsTest,predicted)\n",
    "print CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Precision    Recall\n",
      "Removal of Debris    0.837887  0.827338\n",
      "Desilting of Drain   0.748580  0.683528\n",
      "Others               0.816049  0.858999\n"
     ]
    }
   ],
   "source": [
    "axis0= CM.sum(axis=0)\n",
    "axis1=CM.sum(axis=1)\n",
    "D=CM.diagonal()\n",
    "\n",
    "M=np.zeros([3,2])\n",
    "for i in range(0,3):\n",
    "    for j in range(0,2):\n",
    "        if j==0:\n",
    "            M[i][j]=D[i]/axis0[i]\n",
    "        else: M[i][j]=D[i]/axis1[i]\n",
    "row_labels=['Removal of Debris','Desilting of Drain','Others']\n",
    "column_labels=['Precision','Recall']\n",
    "df = pandas.DataFrame(M, columns=column_labels, index=row_labels)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('start: ', 1521183787.39348, 8004.262279)\n",
      "('End: ', 1521189194.569147, 13409.700587)\n"
     ]
    }
   ],
   "source": [
    "print(\"start: \",time.time(), time.clock())\n",
    "clf2vsAll = svm.SVC(probability=True)\n",
    "clf2vsAll.fit(data, twoVsAllLabels)\n",
    "print(\"End: \",time.time(), time.clock())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clf2vsAllsvm.pkl']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the classifier\n",
    "joblib.dump(clf2vsAll, 'clf2vsAllsvm.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8091759205143191"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2vsAll.score(dataTest,twoVsAllLabelsTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('start: ', 1521190517.539705, 13632.086385)\n",
      "('End: ', 1521190948.812945, 14063.34103)\n"
     ]
    }
   ],
   "source": [
    "print(\"start: \",time.time(), time.clock())\n",
    "adb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,\n",
    "             max_depth=1, random_state=0).fit(data, twoVsAllLabels)\n",
    "print(\"End: \",time.time(), time.clock())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7285213325540619"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adb.score(dataTest,twoVsAllLabelsTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OneVsAll for three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('start: ', 1521192211.118566, 14063.588329)\n"
     ]
    }
   ],
   "source": [
    "print(\"start: \",time.time(), time.clock())\n",
    "ova= OneVsRestClassifier( svm.SVC(probability=True)).fit(data, twoVsAllLabels)\n",
    "print(\"End: \",time.time(), time.clock())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
